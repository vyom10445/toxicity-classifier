# Toxicity Comment Classification

A machine learning project to classify toxic comments using deep learning and NLP techniques.

This repository follows a clean, production-style structure with notebooks for experimentation and modular Python scripts for core logic.

---

## ğŸ“ Project Structure

toxicity-classifier/
â”‚
â”œâ”€â”€ notebooks/ # Jupyter notebooks for experiments & analysis
â”‚ â””â”€â”€ Toxicity.ipynb
â”‚
â”œâ”€â”€ src/ # Core source code (data processing, model, training)
â”‚
â”œâ”€â”€ models/ # Saved trained models (.h5 / .pt)
â”‚
â”œâ”€â”€ data/ # Dataset directory (ignored by git)
â”‚
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md


---

## ğŸ›  Tech Stack

- Python
- TensorFlow / Keras
- NumPy, Pandas
- NLP (Text Vectorization, Embeddings)

---

## ğŸš€ Workflow

1. Experiments and exploration are done in `notebooks/`
2. Reusable logic is moved to `src/`
3. Trained models are saved in `models/`
4. Datasets are kept locally or loaded from external sources

---

## ğŸ“Œ Current Status

- Project structure initialized
- Notebook and directories set up
- Implementation will be added incrementally

---

## ğŸ“„ Notes

- Large datasets are not pushed to GitHub
- Models may be versioned selectively
- This repository is actively being developed
