{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP/MUsYe9DBhW6OH6GlGNdm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vyom10445/toxicity-classifier/blob/main/notebooks/Toxicity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "LHpzSnFpc_YC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/vyom10445/toxicity-classifier.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cik0CCiGP548",
        "outputId": "4b209a2c-410a-4aca-d1ba-4389db274328"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'toxicity-classifier'...\n",
            "remote: Enumerating objects: 41, done.\u001b[K\n",
            "remote: Counting objects: 100% (41/41), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 41 (delta 11), reused 12 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (41/41), 26.45 MiB | 13.84 MiB/s, done.\n",
            "Resolving deltas: 100% (11/11), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"toxicity-classifier\")"
      ],
      "metadata": {
        "id": "YdpvEwmgfoV4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\n",
        "    os.path.join(\n",
        "        \"data\",\n",
        "        \"jigsaw-toxic-comment-classification-challenge\",\n",
        "        \"train.csv\"\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "UXeQWmJjdfs1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import TextVectorization #preprocessing"
      ],
      "metadata": {
        "id": "1_yP92HSgEpG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = df['comment_text']\n",
        "y = df[df.columns[2:]].values"
      ],
      "metadata": {
        "id": "KJF1NJhrgHS2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_FEATURES = 200000 # number of words in the vocab"
      ],
      "metadata": {
        "id": "vTdyO3BegRuI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TextVectorization(max_tokens=MAX_FEATURES,\n",
        "                               output_sequence_length=1800,\n",
        "                               output_mode='int')"
      ],
      "metadata": {
        "id": "ltmeKySdgVGm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.adapt(x.values)"
      ],
      "metadata": {
        "id": "A6tWXRT6gYNO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorized_text = vectorizer(x.values)"
      ],
      "metadata": {
        "id": "ywIauKW3gegg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((vectorized_text, y))\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(160000)\n",
        "dataset = dataset.batch(16)\n",
        "dataset = dataset.prefetch(8) # helps prevent bottlenecks"
      ],
      "metadata": {
        "id": "YGKBI6ehgqGg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = dataset.take(int(len(dataset)*.7))\n",
        "val = dataset.skip(int(len(dataset)*.7)).take(int(len(dataset)*.2))\n",
        "test = dataset.skip(int(len(dataset)*.9)).take(int(len(dataset)*.1))"
      ],
      "metadata": {
        "id": "ao0Sb6-uhR97"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#build a sequential model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,Bidirectional,Dropout,Dense,Embedding"
      ],
      "metadata": {
        "id": "alV5TK_RhYji"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#instantiate our model(instantiate the sequential api)\n",
        "model=Sequential()\n",
        "#create the embedding layer\n",
        "model.add(Embedding(MAX_FEATURES+1,32))\n",
        "#bidirectional LSTM layer\n",
        "model.add(Bidirectional(LSTM(32, activation='tanh')))\n",
        "# Feature extractor Fully connected layers(dense layers)\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dense(256,activation='relu'))\n",
        "model.add(Dense(128,activation='relu'))\n",
        "#Final layer\n",
        "model.add(Dense(6,activation='sigmoid')) #maps to the no. of different of outputs that we have got inside our neural network"
      ],
      "metadata": {
        "id": "J0tvowyVQu7B"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='BinaryCrossentropy', optimizer='Adam')"
      ],
      "metadata": {
        "id": "4tf7x0LYfBv6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train , epochs=1 , validation_data=val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEcG_mEOfMgB",
        "outputId": "90cc2b7b-764a-4430-f471-ca80cd66742d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6981/6981\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m689s\u001b[0m 98ms/step - loss: 0.0811 - val_loss: 0.0464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1wOgT1rLgV_b"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}