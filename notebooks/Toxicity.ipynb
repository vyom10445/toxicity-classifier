{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNINCgXWe+r8fS4XqwiHUWI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vyom10445/toxicity-classifier/blob/main/notebooks/Toxicity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "LHpzSnFpc_YC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/vyom10445/toxicity-classifier.git"
      ],
      "metadata": {
        "id": "cik0CCiGP548"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"toxicity-classifier\")"
      ],
      "metadata": {
        "id": "YdpvEwmgfoV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\n",
        "    os.path.join(\n",
        "        \"data\",\n",
        "        \"jigsaw-toxic-comment-classification-challenge\",\n",
        "        \"train.csv\"\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "UXeQWmJjdfs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import TextVectorization #preprocessing"
      ],
      "metadata": {
        "id": "1_yP92HSgEpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = df['comment_text']\n",
        "y = df[df.columns[2:]].values"
      ],
      "metadata": {
        "id": "KJF1NJhrgHS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_FEATURES = 200000 # number of words in the vocab"
      ],
      "metadata": {
        "id": "vTdyO3BegRuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TextVectorization(max_tokens=MAX_FEATURES,\n",
        "                               output_sequence_length=1800,\n",
        "                               output_mode='int')"
      ],
      "metadata": {
        "id": "ltmeKySdgVGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.adapt(x.values)"
      ],
      "metadata": {
        "id": "A6tWXRT6gYNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorized_text = vectorizer(x.values)"
      ],
      "metadata": {
        "id": "ywIauKW3gegg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((vectorized_text, y))\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(160000)\n",
        "dataset = dataset.batch(16)\n",
        "dataset = dataset.prefetch(8) # helps prevent bottlenecks"
      ],
      "metadata": {
        "id": "YGKBI6ehgqGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = dataset.take(int(len(dataset)*.7))\n",
        "val = dataset.skip(int(len(dataset)*.7)).take(int(len(dataset)*.2))\n",
        "test = dataset.skip(int(len(dataset)*.9)).take(int(len(dataset)*.1))"
      ],
      "metadata": {
        "id": "ao0Sb6-uhR97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#build a sequential model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,Bidirectional,Dropout,Dense,Embedding"
      ],
      "metadata": {
        "id": "alV5TK_RhYji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#instantiate our model(instantiate the sequential api)\n",
        "model=Sequential()\n",
        "#create the embedding layer\n",
        "model.add(Embedding(MAX_FEATURES+1,32))\n",
        "#bidirectional LSTM layer\n",
        "model.add(Bidirectional(LSTM(32, activation='tanh')))\n",
        "# Feature extractor Fully connected layers(dense layers)\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dense(256,activation='relu'))\n",
        "model.add(Dense(128,activation='relu'))\n",
        "#Final layer\n",
        "model.add(Dense(6,activation='sigmoid')) #maps to the no. of different of outputs that we have got inside our neural network"
      ],
      "metadata": {
        "id": "J0tvowyVQu7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='BinaryCrossentropy', optimizer='Adam')"
      ],
      "metadata": {
        "id": "4tf7x0LYfBv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train , epochs=1 , validation_data=val)"
      ],
      "metadata": {
        "id": "VEcG_mEOfMgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#make predictions\n",
        "input_text = vectorizer('You freaking suck! I am going to hit you.')"
      ],
      "metadata": {
        "id": "1wOgT1rLgV_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = model.predict(np.expand_dims(input_text,axis=0))"
      ],
      "metadata": {
        "id": "AqglerSqvoQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(res > 0.5).astype(int)"
      ],
      "metadata": {
        "id": "Cw0zZ9vGvtM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_X, batch_y = test.as_numpy_iterator().next()"
      ],
      "metadata": {
        "id": "yBmJhvZ7yirE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(model.predict(batch_X) > 0.5).astype(int)"
      ],
      "metadata": {
        "id": "bzMX5o7Gyxou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate model\n",
        "from tensorflow.keras.metrics import Precision,Recall,CategoricalAccuracy"
      ],
      "metadata": {
        "id": "_JgoXBxny25-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre=Precision()\n",
        "re=Recall()\n",
        "acc=CategoricalAccuracy()"
      ],
      "metadata": {
        "id": "3EXyJemt1L2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in test.as_numpy_iterator():\n",
        "    # Unpack the batch\n",
        "    X_true, y_true = batch\n",
        "    # Make a prediction\n",
        "    yhat = model.predict(X_true)\n",
        "\n",
        "    # Flatten the predictions\n",
        "    y_true = y_true.flatten()\n",
        "    yhat = yhat.flatten()\n",
        "\n",
        "    pre.update_state(y_true, yhat)\n",
        "    re.update_state(y_true, yhat)\n",
        "    acc.update_state(y_true, yhat)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "jTxYbqSa1VVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Precision: {pre.result().numpy()}, Recall:{re.result().numpy()}, Accuracy:{acc.result().numpy()}')"
      ],
      "metadata": {
        "id": "LEvBL84h3Ebw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test and gradio\n",
        "!pip install gradio jinja2"
      ],
      "metadata": {
        "collapsed": true,
        "id": "orTC0A5S4Vc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "l76uqc4o5JIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('toxicity.h5')"
      ],
      "metadata": {
        "id": "pKfbnsje5kpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_str = vectorizer('hey i freaken hate you!')"
      ],
      "metadata": {
        "id": "Ns4ZnUNa6BUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = model.predict(np.expand_dims(input_str,0))"
      ],
      "metadata": {
        "id": "3sG_Cq6T7NKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "id": "b_VtMpFf7PDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score_comment(comment):\n",
        "    vectorized_comment = vectorizer([comment])\n",
        "    results = model.predict(vectorized_comment)\n",
        "\n",
        "    text = ''\n",
        "    for idx, col in enumerate(df.columns[2:]):\n",
        "        text += '{}: {}\\n'.format(col, results[0][idx]>0.5)\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "LIvadlBt7Qub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interface = gr.Interface(fn=score_comment,\n",
        "                         inputs = gr.Textbox(lines=2, placeholder='Comment to score'),\n",
        "                        outputs=gr.Textbox(lines=10, label=\"Prediction\")\n",
        ")"
      ],
      "metadata": {
        "id": "-uAy7kIC9Y5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interface.launch(share=True)"
      ],
      "metadata": {
        "id": "rS76EBdg9pO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "683__aXrBha9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}